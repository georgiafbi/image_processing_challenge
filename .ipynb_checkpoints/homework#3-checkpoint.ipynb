{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f4c2c16-5a98-45ab-b439-f3c46d221751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34aef299-e089-45b3-a736-d921b220718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_MATCH_COUNT = 10\n",
    "frame_num=0\n",
    "homography_frames_list=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9f06d26-71c6-4b14-88b5-61698fbb83d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#query image\n",
    "img=cv2.imread(\"Book.png\")\n",
    "if img is None:\n",
    "    sys.exit(\"Could not read the image.\")\n",
    "\n",
    "#resizing image to match video size\n",
    "img_resized=cv2.resize(img,(1080,1920),interpolation=cv2.INTER_AREA)\n",
    "\n",
    "#rotating image counterclockwise 90 degrees\n",
    "rotated_img=cv2.rotate(img_resized, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "#gray scale of rotated_img\n",
    "gray_img = cv2.cvtColor(rotated_img, cv2.COLOR_RGB2GRAY)\n",
    "#create a VideoCapture object and read from input file\n",
    "\n",
    "cap = cv2.VideoCapture('BookScene.MOV')\n",
    "#Check if camera opened successfully\n",
    "if (cap.isOpened()==False):\n",
    "    sys.exit(\"Error opening video stream or file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c422b9be-45ab-4741-92d8-4654c151beec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#features\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "#returns keypoints and descriptor for gray_img\n",
    "kpts_img, des_img=sift.detectAndCompute(gray_img,None)\n",
    "\n",
    "# gray_img=cv2.drawKeypoints(gray_img,kpts_img,gray_img)\n",
    "\n",
    "#feature matching\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "search_params = dict(checks = 50)\n",
    "flann = cv2.FlannBasedMatcher(index_params, search_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "31050c18-4d0c-4c8a-81f6-abf236f61b2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-u4kjpz2z\\opencv\\modules\\core\\src\\matmul.dispatch.cpp:531: error: (-215:Assertion failed) scn + 1 == m.cols in function 'cv::perspectiveTransform'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_15908/3605403599.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mh\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrotated_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m             \u001b[0mpts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mh\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m             \u001b[0mdst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperspectiveTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[0mhomography_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolylines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrotated_frame\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLINE_AA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.3) C:\\Users\\runneradmin\\AppData\\Local\\Temp\\pip-req-build-u4kjpz2z\\opencv\\modules\\core\\src\\matmul.dispatch.cpp:531: error: (-215:Assertion failed) scn + 1 == m.cols in function 'cv::perspectiveTransform'\n"
     ]
    }
   ],
   "source": [
    "#Read until video is completed\n",
    "while(cap.isOpened()):\n",
    "    #capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if frame_num >= 10:\n",
    "        break\n",
    "    if ret == True:\n",
    "        #rotate frame 90 degrees\n",
    "        rotated_frame=cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        #converts rotated_frame into gray scale for training image\n",
    "        gray_frame=cv2.cvtColor(rotated_frame,cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        #returns keypoints and descriptor for gray_frame\n",
    "        kpts_gray_frame,des_gray_frame=sift.detectAndCompute(gray_frame,None)\n",
    "        #gray_frame = cv2.drawKeypoints(gray_frame,kpts_gray_frame,gray_frame)\n",
    "    \n",
    "        #returns matches between original image descriptor and frame descriptor\n",
    "        matches=flann.knnMatch(des_img,des_gray_frame,2)\n",
    "        \n",
    "        # store all the good matches as per Lowe's ratio test.\n",
    "        good = []\n",
    "        for m,n in matches:\n",
    "            if m.distance < 0.5*n.distance:\n",
    "                good.append(m)\n",
    "        if len(good)>MIN_MATCH_COUNT:\n",
    "            src_pts = np.float32([ kpts_img[m.queryIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "            dst_pts = np.float32([ kpts_gray_frame[m.trainIdx].pt for m in good ]).reshape(-1,1,2)\n",
    "            matrix, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC,5.0)\n",
    "            matches_mask = mask.ravel().tolist()\n",
    "            h,w,d = rotated_img.shape\n",
    "            pts = np.float32([ [0,0],[0,h-1],[w-1,h-1],[w-1,0] ]).reshape(-1,1,2)\n",
    "            dst = cv2.perspectiveTransform(pts,matrix)\n",
    "            \n",
    "            homography_img = cv2.polylines(rotated_frame,[np.int32(dst)],True,(0,255,0),3, cv2.LINE_AA)\n",
    "            if frame_num <10:\n",
    "                cv2.imwrite(f\"Book Scene Homography #{frame_num+1}.jpg\",homography_img)\n",
    "                homography_frames_list.append(homography_img)\n",
    "                frame_num+=1\n",
    "            cv2.imshow(\"Homography\",homography_img)\n",
    "            \n",
    "        else:\n",
    "            cv2.imshow(\"Homography\",gray_frame)\n",
    "            \n",
    "        #draws matches between images\n",
    "        #img_matches = cv2.drawMatches(gray_img,kpts_img,gray_frame,kpts_gray_frame,good,gray_frame)\n",
    "    \n",
    "        #Display the resulting frame and gray_img\n",
    "        #cv2.imshow('Image', gray_img)\n",
    "        #cv2.imshow('Gray Frame', gray_frame)\n",
    "        #cv2.imshow('Matches', img_matches)\n",
    "        #Press Q on keyboard to exit\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    #break loop\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "#when everything done, release the video capture object\n",
    "cap.release()\n",
    "#Closes all the frames()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e4ee34d-1b31-4209-9574-843be126ae6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def img_feature_matching(img1, img2, mMCount):\n",
    "#     #Initiate SIFT detector, Scale-Invariant Feature Transform\n",
    "#     sift = cv2.SIFT_create()\n",
    "#     #find the keypoints and descriptors with SIFT\n",
    "#     kp1,des1 =sift.detectAndCompute(img1,None)\n",
    "#     kp2,des2=sift.detectAndCompute(img2,None)\n",
    "    \n",
    "#     FLANN_INDEX_KDTREE = 1\n",
    "    \n",
    "#     index_params=dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
    "    \n",
    "#     search_params = dict(checks=50)\n",
    "    \n",
    "#     flann =cv2.FlannBasedMatcher(index_params,search_params)\n",
    "    \n",
    "#     matches = flann.knnMatch(des1,des2,k=2)\n",
    "    \n",
    "#     #store all the good matches as per Lowe's ratio test\n",
    "    \n",
    "#     for m,n in matches:\n",
    "#         if m.distance < 0.7*n.distance:\n",
    "#             good.append(m)\n",
    "            \n",
    "#     if len(good) > mMCount:\n",
    "#         src_pts=np.float32(kp1[m.queryIdx].pt for m in good ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df903b9-884c-45fd-bc29-ac38b9e68652",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff09a8c-d743-4c04-a404-416d5cfbd9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
